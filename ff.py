from nltk.tokenize import word_tokenize
sample_text = "Hello, world!"
tokens = word_tokenize(sample_text)
print(tokens)
